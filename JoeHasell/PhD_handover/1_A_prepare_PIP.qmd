---
title: "Appendix 1.A: Preparing PIP inequality data"
format: html
warning: false

---

# Processing steps

The titles in each of the boxes below summarise the steps taken to prepare the PIP data. In each case you can expand the box to see the code used.

::: {.callout-note collapse="true" appearance="minimal"}
### Packages and settings

```{python}

import pandas as pd
import plotly.express as px
import statsmodels.formula.api as smf

# import json
# import requests

```


::: {.callout-note collapse="true" appearance="minimal"}
### Extract and save PIP percentile data

I haven't been able to find a way to make this work.... Currently I just manually save the file from https://datacatalog.worldbank.org/search/dataset/0063646

```{python}


# url = "https://datacatalogfiles.worldbank.org/ddh-published/0063646/DR0090251/world_100bin.csv?versionId=2023-04-21T06:30:28.7988867Z"

# df = pd.read_csv(url)

# df
```

:::


::: {.callout-note collapse="true" appearance="minimal"}
### Load PIP percentile data
```{python}
fp = "data/original/pip_percentiles.csv"

df_pip_percentiles = pd.read_csv(fp)



```

:::



::: {.callout-note collapse="true" appearance="minimal"}
### Keep top 1% shares
```{python}

drop_cols = ['percentile', 'avg_welfare', 'pop_share', 'quantile']

df_pip_percentiles = df_pip_percentiles[df_pip_percentiles['percentile'] == 100]\
  .drop(drop_cols, axis=1)\
  .rename(columns={
    'welfare_share': 'Top 1pc share'
  })


# Convert shares to percent
df_pip_percentiles['Top 1pc share'] = df_pip_percentiles['Top 1pc share'] * 100
```

:::

::: {.callout-note collapse="true" appearance="minimal"}
### Standardize country names in percentile data


```{python}
# # Initially I save a csv of country-codes included in the percentil data, to pass through the OWID country name standardization tool
# unique_countries = df_pip_percentiles['country_code'].unique()
# df_pip_percentiles_countries = pd.DataFrame({'country': unique_countries})

# df_pip_percentiles_countries.to_csv('data/original/pip_percentiles_countries.csv', index=False)


# Read in name mapping file
fp = 'data/original/pip_percentiles_countries_country_standardized.csv'
name_mapping = pd.read_csv(fp)


# Merge into  

# Merge mapping into data

df_pip_percentiles = pd.merge(df_pip_percentiles, name_mapping, left_on='country_code', right_on='country', how = 'left')

# Drop columns used in the construction of the standardized country column
df_pip_percentiles = df_pip_percentiles.drop(columns=['country','country_code'])

df_pip_percentiles = df_pip_percentiles.rename(columns = {'Our World In Data Name': 'country'})
```

```{python}
df_pip_percentiles.head()
```
:::


::: {.callout-note collapse="true" appearance="minimal"}
### Compare top 1% shares as estimated by Gpinter

```{python}


fp = "data/manipulation/pip_estimated_top1_shares.csv"

estimated_shares = pd.read_csv(fp)

compare = pd.merge(df_pip_percentiles, estimated_shares, how = 'outer')

compare['diff'] = compare['Top 1pc share'] - compare['top1_share_gpinter']*100

# compare.head()

# fig = px.scatter(compare, x='Top 1pc share', y="top1_share_gpinter")
# fig.show()

fig = px.scatter(compare,x="top1_share_gpinter", y = 'diff', color = 'country')
fig.show()


```

:::

::: {.callout-note collapse="true" appearance="minimal"}
### Load PIP main data (already prepared by OWID)
We load the data from a file prepared from the PIP API by Our World in Data.

```{python}
# df_pip = pd.read_csv("https://raw.githubusercontent.com/owid/poverty-data/main/datasets/pip_dataset.csv")

#  A local version, in case internet isn't available 
df_pip = pd.read_csv("data/original/pip_dataset.csv")

```

The dataframe looks like this:
```{python}
df_pip.head()
```
:::

::: {.callout-note collapse="true" appearance="minimal"}
### Select PPP version
We will use the 2017 PPPs.
```{python}
df_pip = df_pip.loc[df_pip["ppp_version"] == 2017]
```
:::

::: {.callout-note collapse="true" appearance="minimal"}
### Merge top 1% shares from percentile data into main PIP data

```{python}
df_pip = pd.merge(df_pip, df_pip_percentiles, on=['country', 'year', 'reporting_level', 'welfare_type'], how='left')

df_pip.head()
```
:::


::: {.callout-note collapse="true" appearance="minimal"}
### Drop sub-national data

The PIP data includes observations for national, urban and rural populations (`reporting_level`):

```{python}
df_pip.groupby('reporting_level').count()
```

Here we add a count of the number of reporting levels per country-year.
```{python}
df_pip['n_reporting_level'] = df_pip\
  .groupby(["country", "year"])['reporting_level']\
  .transform('count')

df_pip.head(20)  
```

We only want one reporting level for each country-year.

That is already true for most country-years. But some include all three reporting levels.
```{python}
df_pip.groupby('n_reporting_level').count()

```

Here are the countries which include all three reporting levels:
```{python}

multi_reporting_level_countries = df_pip.loc[df_pip['n_reporting_level'] == 3, "country"].unique()

multi_reporting_level_countries

```


For the country-years with 3 reporting levels, we keep only the national estimates. 
```{python}
df_pip = df_pip.loc[(df_pip['n_reporting_level'] != 3) | (df_pip['reporting_level'] == 'national') ]
```

:::


::: {.callout-note collapse="true" appearance="minimal"}
### Drop regional data

The dataset includes aggregated estiates for world regions.

Here we define a list of these aggregate entities and drop them from the data.

```{python}
drop_aggs = [
  "East Asia and Pacific",
  "South Asia",
  "Europe and Central Asia",
  "High income countries",
  "Latin America and the Caribbean",
  "Middle East and North Africa",
  "Sub-Saharan Africa",
  "World"
]

df_pip = df_pip.loc[~df_pip.country.isin(drop_aggs)]

```
:::


::: {.callout-note collapse="true" appearance="minimal"}
### Calculate additional variables

```{python}

# Bottom 50% share – sum shares of lower 5 deciles
sum_cols = [
  "decile1_share",
  "decile2_share",
  "decile3_share",
  "decile4_share",
  "decile5_share"]

df_pip["Bottom 50pc share"] = df_pip[sum_cols].sum(axis=1)

df_pip["P90:P50 ratio"] = df_pip["decile9_thr"]/df_pip["median"]

df_pip["Gini"] = df_pip['gini'] * 100

# Top 10 / bottom 50% share
df_pip["Ratio Top 10 Bottom 50 share"] = df_pip["decile10_share"]/df_pip["Bottom 50pc share"] * 100

```

:::

::: {.callout-note collapse="true" appearance="minimal"}
### Rename and select needed columns

```{python}

df_pip = df_pip.rename(columns={
    'decile10_share':'Top 10pc share',
    'mld': 'MLD',
    "country": "Entity",
    "year": "Year"
  })

keep_cols = [
  "Year",
  "Entity",
  "Gini",
  "Top 1pc share",
  "Top 10pc share",
  "Bottom 50pc share",
  "Ratio Top 10 Bottom 50 share",
  "MLD",
  "welfare_type"
]

df_pip = df_pip[keep_cols]

```

:::



::: {.callout-note collapse="true" appearance="minimal"}
### See the prepared PIP data

The first 100 rows of the dataframe looks like this:
```{python}
df_pip.head(100)
```

:::

::: {.callout-note collapse="true" appearance="minimal"}
### Save the data
I save the prepared data locally:
```{python}
df_pip.to_csv("data/clean/pip.csv", index=False)
```
:::



## Important notes

### Income and consumption data in PIP
The PIP data includes a mix of income and consumption observations – including both for some country-years.

